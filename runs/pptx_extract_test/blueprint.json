{
  "schema_version": "0.1",
  "document_id": "2",
  "theme_id": "theme_default",
  "slides": [
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "[IMAGE]",
          "2026年2月15日 | Generated by Genspark AI Slides",
          "[IMAGE]",
          "Technical Research Report",
          "ローカルAI 技術調査レポート",
          "オンデバイス／ローカル推論の現実解と推奨スタック",
          "[IMAGE]",
          "LLM"
        ]
      },
      "citations": [
        {
          "mark": "※1",
          "page": 1,
          "chunk_id": "s001_sh002"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "このスライドの読み方",
      "slots": {
        "TITLE": "このスライドの読み方",
        "BULLETS": [
          "概要→詳細の二層構造ガイド",
          "[IMAGE]",
          "構造：二層設計",
          "[IMAGE]",
          "1. 概要スライド（Executive Summary）",
          "意思決定に必要な「結論」と「要点」を最初に提示します。時間がない場合はここだけ読めば全体像が掴めます。",
          "[IMAGE]",
          "2. 完全版スライド（Full Detail）"
        ]
      },
      "citations": [
        {
          "mark": "※2",
          "page": 2,
          "chunk_id": "s002_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "Local AI Technical Report",
          "目次（Agenda）",
          "Total 13 Chapters",
          "01",
          "タイトル／目的／読み方",
          "レポートの目的と、概要→詳細の二層構造の活用方法。",
          "02",
          "エグゼクティブサマリ"
        ]
      },
      "citations": [
        {
          "mark": "※3",
          "page": 3,
          "chunk_id": "s003_sh003"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "エグゼクティブサマリ（実務要点）",
      "slots": {
        "TITLE": "エグゼクティブサマリ（実務要点）",
        "BULLETS": [
          "ローカルAI導入における意思決定の重要ポイント",
          "結論：ローカルAIは「4bit量子化＋KV管理」を前提に、\n GGUF/llama.cpp系とOllama/LM Studio/MLXで実務化可能です。",
          "[IMAGE]",
          "定義とスコープ",
          "推論が端末orローカルLAN内で完結",
          "入力データは外部へ送信されない",
          "LANサーブ含む（LM Studio, Ollama）",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※4",
          "page": 4,
          "chunk_id": "s004_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "エグゼクティブサマリ（詳細1）",
          "ローカルAIの定義と中核技術",
          "[IMAGE]",
          "結論：ローカルAIは「推論がユーザー管理下で完結する構成」と定義され、 \n重み量子化（4bit）とKVキャッシュ最適化が実運用の技術的基盤です。",
          "[IMAGE]",
          "ローカルAIの定義と射程",
          "[IMAGE]",
          "ユーザー端末（オンデバイス）、PC、またはローカルLAN内サーバで完結。"
        ]
      },
      "citations": [
        {
          "mark": "※5",
          "page": 5,
          "chunk_id": "s005_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "エグゼクティブサマリ（詳細2）",
          "実運用ランタイムとハードウェア実用ライン",
          "[IMAGE]",
          "結論：ランタイムはllama.cpp/GGUF系・MLXが第一選択となり、ハードウェアはメモリ容量でTier化されます（長文はKV支配）。",
          "[IMAGE]",
          "実運用ランタイム（第一選択）",
          "[IMAGE]",
          "クロスプラットフォーム標準："
        ]
      },
      "citations": [
        {
          "mark": "※6",
          "page": 6,
          "chunk_id": "s006_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "エグゼクティブサマリ（詳細3）",
          "推奨スタック3パターン（Tier別構成案）",
          "結論：用途とリソースに応じて「低コスト／高品質／ハード制約」の3構成を選択します。\n※各構成の具体的な失敗モードと回避策は、後述の「ユースケース別推奨スタック」章で詳細に展開します。",
          "[IMAGE]",
          "低コスト構成",
          "Target HW",
          "[IMAGE]",
          "CPUのみ / エントリーGPU / Apple 16GB"
        ]
      },
      "citations": [
        {
          "mark": "※7",
          "page": 7,
          "chunk_id": "s007_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "ローカルAIの定義とスコープ",
          "Definition & Scope",
          "DEFINITION",
          "本資料の「ローカルAI」とは、推論がユーザー管理下（端末／ローカルPC／ローカルLAN）で完結し、入力データが外部へ送信されない構成を指します。",
          "[IMAGE]",
          "スコープの射程（範囲）",
          "[IMAGE]",
          "ローカルAPIサーバを含む:\nlocalhostだけでなく、LAN公開（network）された推論サーバも対象。"
        ]
      },
      "citations": [
        {
          "mark": "※8",
          "page": 8,
          "chunk_id": "s008_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "未指定事項の扱い（前提条件）",
          "オフライン要件・対象OS・ライセンス",
          "[IMAGE]",
          "結論：「完全オフライン」は推論実行時のみを必須要件とし、 \n 導入・更新時のネットワーク利用は許容する現実的な設計を前提とします。",
          "[IMAGE]",
          "オフライン要件と対象OS",
          "[IMAGE]",
          "“完全オフライン”の定義："
        ]
      },
      "citations": [
        {
          "mark": "※9",
          "page": 9,
          "chunk_id": "s009_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "04",
          "[IMAGE]",
          "ローカルAI\nランドスケープ",
          "オンデバイス実行環境の\n全体像と技術スタック",
          "KEY TAKEAWAYS",
          "[IMAGE]",
          "本章の要点",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※10",
          "page": 10,
          "chunk_id": "s010_sh003"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "ローカルAIランドスケープ",
          "カテゴリ網羅・代表モデルとランタイムの関係図",
          "[IMAGE]",
          "Local AI Technical Survey Report 2026",
          "11 / 80",
          "結論：ローカルAIは9カテゴリ（LLM/VLM/ASR/TTS/Embedding/OCR/画像生成/Agent/音声前処理）で構成され、\n モデル系とランタイム系が実務上の結節点となります。",
          "Core (AI Category)",
          "Model Examples"
        ]
      },
      "citations": [
        {
          "mark": "※11",
          "page": 11,
          "chunk_id": "s011_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "ローカルAIランドスケープ（詳細）",
          "カテゴリ別代表モデル・ランタイム・主用途",
          "[IMAGE]",
          "結論：実務上の収束点は「LLMはGGUF (llama.cpp)かGPU量子化系」「macOSはMLX/Unified Memory最適化」「WindowsはOllama/LM Studio + 必要に応じWSL2」。",
          "[IMAGE]",
          "テキストLLM",
          "形式:",
          "GGUF (llama.cpp必須), GPTQ/AWQ/EXL2 (GPU向け)"
        ]
      },
      "citations": [
        {
          "mark": "※12",
          "page": 12,
          "chunk_id": "s012_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "[IMAGE]",
          "05",
          "[IMAGE]",
          "特徴軸（評価軸）\nの定義",
          "評価の共通物差しと\n測定基準",
          "KEY TAKEAWAYS",
          "[IMAGE]",
          "本章の要点"
        ]
      },
      "citations": [
        {
          "mark": "※13",
          "page": 13,
          "chunk_id": "s013_sh003"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "Evaluation Metrics Overview",
          "特徴軸（評価軸）の定義",
          "Total 13 Metrics",
          "01",
          "指示追従 (Instruction Following)",
          "プロンプトの制約・禁止事項・形式指定（箇条書き禁止等）を遵守する能力。",
          "02",
          "幻覚耐性 (Hallucination Resistance)"
        ]
      },
      "citations": [
        {
          "mark": "※14",
          "page": 14,
          "chunk_id": "s014_sh003"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "特徴軸（詳細）：測定と設計含意",
      "slots": {
        "TITLE": "特徴軸（詳細）：測定と設計含意",
        "BULLETS": [
          "13の評価軸における計測手順と技術的背景",
          "[IMAGE]",
          "機能・性能評価のコア",
          "[IMAGE]",
          "JSON堅牢性と指示追従",
          "ツール呼び出し等の業務連携ではスキーマ破壊が致命的。Ollama/LM StudioのOpenAI互換APIを用いて同一条件で比較検証を行う。llama-cpp-python等のランタイム依存機能（response_format）も活用。",
          "[IMAGE]",
          "[24]"
        ]
      },
      "citations": [
        {
          "mark": "※15",
          "page": 15,
          "chunk_id": "s015_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "06",
          "[IMAGE]",
          "カテゴリ別\nモデルカタログ",
          "主要9カテゴリの\n詳細データと採用判断",
          "SECTION OVERVIEW",
          "[IMAGE]",
          "提示方針：三層構造",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※16",
          "page": 16,
          "chunk_id": "s016_sh003"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "テキストLLM（汎用）概要",
          "主要7モデルと実運用環境",
          "[IMAGE]",
          "結論：ローカル実務のボリュームゾーンは7B〜14B（4bit）。 \n 形式はGGUF（llama.cpp系）かGPU量子化（GPTQ/AWQ/EXL2）の二択が現実解です。",
          "[IMAGE]",
          "代表モデル群（要点）",
          "[IMAGE]",
          "Llama 3.1 Instruct: 8B/70B/405B系。多言語対話最適化を明記。"
        ]
      },
      "citations": [
        {
          "mark": "※17",
          "page": 17,
          "chunk_id": "s017_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "テキストLLM（完全版表1）",
          "主要モデル詳細比較：Llama 3.1 / Qwen2.5 / Gemma 2 / Mixtral",
          "[TABLE]",
          "[IMAGE]",
          "採用判断の要点：ローカル実務のボリュームゾーンは7B〜14B級（4bit）です。3B級はハード制約時、32B以上は高品質要件時（メモリ増設前提）に選択します。ライセンスはファミリー内でも異なる場合があるため、必ず最新のモデルカードを確認してください。",
          "Page 18 | ローカルAI 技術調査レポート 2026",
          "Data Source: Technical Survey Report [29-37]"
        ]
      },
      "citations": [
        {
          "mark": "※18",
          "page": 18,
          "chunk_id": "s018_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "テキストLLM（完全版表2）",
          "主要モデル詳細比較：Phi-3 Mini / Phi-4 / gpt-oss",
          "[TABLE]",
          "[IMAGE]",
          "採用判断の要点：14Bクラス（Phi-4等）はローカル運用の「上位実用ライン」であり、32GB以上のメモリ環境が推奨されます。長文コンテキスト（128K等）を活用する場合は、モデルサイズだけでなくKVキャッシュのメモリ消費が支配的になるため、メモリ設計（KV量子化やコンテキスト長制限）が不可欠です。",
          "Page 19 | ローカルAI 技術調査レポート 2026",
          "Data Source: Technical Survey Report [38-41]"
        ]
      },
      "citations": [
        {
          "mark": "※19",
          "page": 19,
          "chunk_id": "s019_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "採用判断基準（テキストLLM）",
          "選定フローと実務上の重要ポイント",
          "[IMAGE]",
          "結論：モデル選定は「必要品質→許容レイテンシ→許容メモリ→形式→ランタイム」の順に行うのが、実務上最も破綻しにくいフローです。",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※20",
          "page": 20,
          "chunk_id": "s020_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "VLM/LMM 概要（画像理解・マルチモーダル）",
          "カテゴリ別モデルカタログ",
          "[IMAGE]",
          "結論：ローカル運用の現実ラインは2B/7B級が中心。 \n 画像トークン化の前処理依存が強く、ランタイムの明示サポートが重要です。",
          "[IMAGE]",
          "代表モデルと特徴",
          "[IMAGE]",
          "Qwen2-VL (2B/7B/72B)"
        ]
      },
      "citations": [
        {
          "mark": "※21",
          "page": 21,
          "chunk_id": "s021_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "VLM/LMM（完全版表）",
          "Qwen2-VL / Phi-3-Vision / InternVL2 / LLaVA 詳細比較",
          "[TABLE]",
          "[IMAGE]",
          "採用判断の要点：画像理解はテキストLLMより前処理・プロセッサ依存が強いため、「ランタイムがそのモデルを明示サポートしているか」を一次確認してください（例：MLX-VLMがQwen2-VLのコマンド提示）。72B級はローカルでは上位機（96GB+等）が必要で、現実は2B/7B級で設計します。",
          "Page 22 | ローカルAI 技術調査レポート 2026",
          "Data Source: Technical Survey Report [28, 42-47]"
        ]
      },
      "citations": [
        {
          "mark": "※22",
          "page": 22,
          "chunk_id": "s022_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "採用判断基準（VLM/LMM）",
          "ランタイム適合性と運用設計",
          "[IMAGE]",
          "結論：画像理解は前処理・プロセッサ依存が強いため、「ランタイムの明示サポート確認」が最優先です。2B/7B級を基本とし、不足分をRAG/OCRで補うのが安全策です。",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※23",
          "page": 23,
          "chunk_id": "s023_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "ASR（音声認識）概要",
          "カテゴリ別モデルカタログ",
          "[IMAGE]",
          "結論：ローカルASRは「RTF・メモリ・誤転記」の同時最適化が必須。\nfaster-whisperを基準実装とし、速度と精度（幻覚抑制）のバランスを図ります。",
          "[IMAGE]",
          "Whisper系実装の比較",
          "[TABLE]",
          "主な技術要素:"
        ]
      },
      "citations": [
        {
          "mark": "※24",
          "page": 24,
          "chunk_id": "s024_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "ASR（完全版表）",
          "主要モデル・方式比較：Whisper / faster-whisper / whisper.cpp",
          "[TABLE]",
          "[IMAGE]",
          "採用判断の要点：ローカルASRは「RTF（実時間比）」「メモリ」「誤転記リスク」の3要素を同時に満たす必要があります。faster-whisperは速度・メモリ面での利点を明示しているため、まずはこれを基準実装として検証し、要件に応じてGPU化やモデルサイズの調整を行うのが合理的です。",
          "Page 25 | ローカルAI 技術調査レポート 2026",
          "Data Source: Technical Survey Report [48-51]"
        ]
      },
      "citations": [
        {
          "mark": "※25",
          "page": 25,
          "chunk_id": "s025_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "採用判断基準（ASR）",
          "RTF要件と誤転記リスクに基づく選定フロー",
          "[IMAGE]",
          "結論：faster-whisperを基準実装とし、RTF要件・誤転記リスクに応じてGPU化やモデル拡大を検討する段階的最適化が合理的です。",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※26",
          "page": 26,
          "chunk_id": "s026_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "TTS（音声合成）概要",
          "読み上げと音声クローンの分離設計",
          "[IMAGE]",
          "結論：「読み上げ」は軽量モデル（Piper/Kokoro）で常駐化し、 \n 「音声クローン」は高品質モデル（XTTS/StyleTTS2）で分離設計します。",
          "[IMAGE]",
          "代表システムと特徴",
          "[IMAGE]",
          "Piper: \"fast, local neural TTS\"を標榜。省リソース・常駐向き。"
        ]
      },
      "citations": [
        {
          "mark": "※27",
          "page": 27,
          "chunk_id": "s027_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "TTS（完全版表）",
          "主要モデル詳細比較：Piper / Kokoro / XTTS-v2 / StyleTTS2",
          "[TABLE]",
          "[IMAGE]",
          "採用判断の要点：「読み上げ（通知・要約）」と「クローン（本人声）」は別物として分離設計します。前者はPiper/Kokoroのような軽量系、後者はXTTS等で、法務・倫理リスク管理を別レイヤに置きます。",
          "[IMAGE]",
          "[56]",
          "Page 28 | ローカルAI 技術調査レポート 2026"
        ]
      },
      "citations": [
        {
          "mark": "※28",
          "page": 28,
          "chunk_id": "s028_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "採用判断基準（TTS）",
          "品質・コスト・リスクの分離管理",
          "[IMAGE]",
          "結論：「読み上げ（通知・要約）」と「クローン（本人声）」は別レイヤで運用すべきです。前者は軽量化し、後者は法務・倫理リスクを管理します。",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※29",
          "page": 29,
          "chunk_id": "s029_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "Embedding / Reranker 概要",
          "検索・RAG基盤モデル",
          "[IMAGE]",
          "結論：RAGシステムの品質上限はEmbeddingの検索精度で決まります。 \n まずBGE-M3等でRecallを確保し、RerankerでPrecisionを向上させる二段構えが定石です。",
          "[IMAGE]",
          "Embedding (ベクトル検索)",
          "[IMAGE]",
          "Retrieval"
        ]
      },
      "citations": [
        {
          "mark": "※30",
          "page": 30,
          "chunk_id": "s030_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "Embedding/Reranker（完全版表）",
          "検索・RAG基盤：BGE-M3 / multilingual-e5 / bge-reranker",
          "[TABLE]",
          "[IMAGE]",
          "採用判断の要点：RAGの失敗の多くは「検索外れ」「上位が弱い」「文脈過多」です。EmbeddingでRecallを確保し、rerankerでPrecisionを上げる二段構えが実務的推奨です。ローカル運用では、Embeddingの前計算（夜間バッチ）により実時間の負荷をLLM応答に集中させる設計が有効です。",
          "Page 31 | ローカルAI 技術調査レポート 2026",
          "Data Source: Technical Survey Report [58-62]"
        ]
      },
      "citations": [
        {
          "mark": "※31",
          "page": 31,
          "chunk_id": "s031_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "採用判断基準（Embedding / Reranker）",
          "検索精度と運用安定化のための二段構え設計",
          "[IMAGE]",
          "結論：Embeddingで網羅性(Recall)を確保し、Rerankerで精度(Precision)を上げる「二段構え」が実務的な最適解です。",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]",
          "運用の安定化"
        ]
      },
      "citations": [
        {
          "mark": "※32",
          "page": 32,
          "chunk_id": "s032_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "OCR / Document AI 概要",
          "スキャン品質と構造化要件に基づく手法選択",
          "[IMAGE]",
          "結論：スキャン品質やレイアウトの複雑度に応じて、 \n古典的OCRとOCR-free（Doc理解）を使い分けるハイブリッド戦略が推奨されます。",
          "[IMAGE]",
          "代表的なシステム・モデル",
          "[IMAGE]",
          "Tesseract OCR"
        ]
      },
      "citations": [
        {
          "mark": "※33",
          "page": 33,
          "chunk_id": "s033_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "OCR / Document AI（完全版表）",
          "主要モデル詳細比較：Tesseract / PaddleOCR / Donut / LayoutLMv3",
          "[TABLE]",
          "[IMAGE]",
          "レイアウト保持の重要性：RAGにおいて、単なるテキスト化では図表やレイアウト構造に含まれる情報が欠落しがちです。PaddleOCRの構造化出力や、Donut/LayoutLMv3のようなDocument AIモデルを活用し、レイアウト情報を保持することが検索精度の向上に直結します。",
          "Page 34 | ローカルAI 技術調査レポート 2026",
          "Data Source: Technical Survey Report [64, 66, 68, 69]"
        ]
      },
      "citations": [
        {
          "mark": "※34",
          "page": 34,
          "chunk_id": "s034_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "OCR/Document AI採用判断基準",
          "リスク緩和のためのUX要件とハイブリッド構成",
          "[IMAGE]",
          "結論：誤読リスクをゼロにはできない前提で、前処理の標準化と「原文引用」による人間系確認のUXを要件化します。",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※35",
          "page": 35,
          "chunk_id": "s035_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "画像生成（Diffusion）概要",
          "モデル・ランタイム・実務ポイント",
          "[IMAGE]",
          "結論：画像生成はSDXLを軸に、ComfyUI/SD WebUIで運用。\n FLUX等はライセンス精査が必須であり、VRAM要件はワークフローに依存します。",
          "[IMAGE]",
          "主要モデルとUI（Runtime）",
          "[IMAGE]",
          "高品質生成の標準モデル。ライセンス確認の上、低コスト構成の軸に。"
        ]
      },
      "citations": [
        {
          "mark": "※36",
          "page": 36,
          "chunk_id": "s036_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "画像生成（完全版表）",
          "主要モデル・UI詳細比較：SDXL / ComfyUI / SD WebUI / FLUX",
          "[TABLE]",
          "[IMAGE]",
          "採用判断の要点：VRAM容量が最大の制約となります。解像度、バッチサイズ、ステップ数を固定したプロファイルを作成し、VRAM不足を防ぐ運用設計が重要です。特にFLUX等の最新・上位モデルを採用する場合は、ライセンス条件（商用利用制限など）を事前に入念に確認してください。",
          "Page 37 | ローカルAI 技術調査レポート 2026",
          "Data Source: Technical Survey Report [71-76]"
        ]
      },
      "citations": [
        {
          "mark": "※37",
          "page": 37,
          "chunk_id": "s037_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "\\\\n\\\\n採用判断基準（画像生成）\\\\n",
      "slots": {
        "TITLE": "\\\\n\\\\n採用判断基準（画像生成）\\\\n",
        "BULLETS": [
          "VRAM制約と再現性の担保",
          "\\\\n 結論：VRAM制約に合わせて解像度/バッチ/ステップを固定し、ワークフローを資産化して再現性を担保します。\\\\n",
          "1",
          "VRAM制約",
          "ハードウェア上限を\nまず確認",
          "2",
          "解像度固定",
          "VRAMに収まる\n最大サイズを決定"
        ]
      },
      "citations": [
        {
          "mark": "※38",
          "page": 38,
          "chunk_id": "s038_sh001"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "Agent / Tool-use 概要",
          "ローカル環境でのエージェント構築と実行",
          "[IMAGE]",
          "結論：Agentは「LLM＋ツール呼び出し（関数）＋実行環境」で構成され、Ollama/LM StudioのOpenAI互換APIを用いることで、ローカルでの実務的な構築が現実化しています。",
          "[IMAGE]",
          "構成要素とAPI基盤",
          "[IMAGE]",
          "エージェントの基本構成。LLMが判断し、定義されたツール（関数）を呼び出し、ローカル環境で実行して結果を返すループ構造。"
        ]
      },
      "citations": [
        {
          "mark": "※39",
          "page": 39,
          "chunk_id": "s039_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "Agent/Tool-use（完全版表）",
          "OpenAI互換API / Function Calling / 実装基盤の詳細比較",
          "[TABLE]",
          "[IMAGE]",
          "実装のポイント：安定運用の鍵は「JSONスキーマの固定」と「パラメータ（温度/top_p）の固定」です。幻覚（Hallucination）による不正な関数呼び出しを防ぐため、実行前に許可された関数リストと照合するホワイトリスト方式を推奨します。また、トラブルシューティング用にAPIの要求・応答ログを必ず保存してください。",
          "Page 40 | ローカルAI 技術調査レポート 2026",
          "Data Source: Technical Survey Report [2,3,19,23,24,27,41]"
        ]
      },
      "citations": [
        {
          "mark": "※40",
          "page": 40,
          "chunk_id": "s040_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "採用判断基準（Agent / Tool-use）",
          "JSONスキーマ固定と検証ループによる安全運用",
          "[IMAGE]",
          "結論：JSONスキーマ固定＋検証ループ（自動チェック）による安全運用を基本とし、Ollama/LM StudioのOpenAI互換APIで実装を統一します。",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※41",
          "page": 41,
          "chunk_id": "s041_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "音声周辺（VAD/話者分離/ウェイクワード/ノイズ除去）概要",
          "カテゴリ別モデルカタログ",
          "[IMAGE]",
          "結論：前処理（VAD/話者分離/ウェイクワード/ノイズ除去）が音声UXの品質下限を決定します。\nSilero VADによる無音除去とpyannote.audioによる話者分離が実務上の標準構成です。",
          "[IMAGE]",
          "主要コンポーネント（Primary）",
          "[IMAGE]",
          "VAD（Voice Activity Detection）：Silero VAD"
        ]
      },
      "citations": [
        {
          "mark": "※42",
          "page": 42,
          "chunk_id": "s042_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "音声周辺（完全版表）",
          "Silero VAD / pyannote / openWakeWord / RNNoise 詳細比較",
          "[TABLE]",
          "[IMAGE]",
          "設計の推奨：会議系ワークフローでは「VAD → ASR → 要約」の直列処理を基本とし、負荷の高い話者分離（pyannote等）は必要時のみ追加する設計が実用的です。すべての音声に一律で話者分離を適用すると、処理時間（RTF）が大幅に悪化する可能性があります。",
          "Page 43 | ローカルAI 技術調査レポート 2026",
          "Data Source: Technical Survey Report [14, 82, 84, 85]"
        ]
      },
      "citations": [
        {
          "mark": "※43",
          "page": 43,
          "chunk_id": "s043_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "採用判断基準（音声周辺）",
          "前処理パイプライン標準化と品質管理",
          "[IMAGE]",
          "結論：前処理パイプラインを標準化し、閾値・モデルバージョン・RTF目標を固定することで、UXの品質下限を担保します。",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※44",
          "page": 44,
          "chunk_id": "s044_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "07",
          "[IMAGE]",
          "メモリ設計の\nコア",
          "重み量子化・KVキャッシュ管理と\n最適化技術",
          "KEY TAKEAWAYS",
          "[IMAGE]",
          "本章の要点",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※45",
          "page": 45,
          "chunk_id": "s045_sh003"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "メモリ設計のコア（概要）",
          "重み量子化とKVキャッシュの支配性",
          "[IMAGE]",
          "結論：ローカルAIのメモリ制約は、「重み4bit量子化」と「KVキャッシュ最適化」の2点によって決定される支配的な要因です。",
          "[IMAGE]",
          "重みメモリ（Weights）",
          "[IMAGE]",
          "パラメータ数とbit幅で物理的な下限が決まります。"
        ]
      },
      "citations": [
        {
          "mark": "※46",
          "page": 46,
          "chunk_id": "s046_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "重みメモリ理論値（完全版表1：0.5B〜14B）",
          "モデル規模別 推奨メモリ容量（+10%オーバーヘッド込み概算）",
          "[TABLE]",
          "[IMAGE]",
          "計算根拠：上記数値は「パラメータ数 × bit幅 ÷ 8」に、ランタイムオーバヘッドとして約10%を加算した概算理論値です。これらは重みのみのメモリ消費であり、実運用ではこれに加えてKVキャッシュ（コンテキスト長に比例）が必要となります。特に7B〜14Bモデルは、8GB/16GBメモリ環境での動作可否の境界線となるため、4bit量子化の活用が実務上必須となります。",
          "Page 47 | ローカルAI 技術調査レポート 2026",
          "Data Source: Technical Survey Report (Calculated Estimates)"
        ]
      },
      "citations": [
        {
          "mark": "※47",
          "page": 47,
          "chunk_id": "s047_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "重みメモリ理論値（完全版表2：27B〜70B）",
          "大規模モデル（4bit/INT8/FP16）のメモリ要件",
          "[TABLE]",
          "[IMAGE]",
          "計算前提： パラメータ数 × bit幅 ÷ 8 で基本容量を算出後、実運用におけるランタイムオーバヘッド等を考慮して約+10%を加算した概算値です。",
          "設計含意： 30B級モデルの実運用には、4bit量子化でも約16-18GiBのVRAM/統合メモリが必要です。70B級では4bitでも約36GiBを消費するため、Apple Silicon 64GB/96GBや、VRAM 24GB×2枚構成などの上位ハードウェア構成が現実的なラインとなります。",
          "Page 48 | ローカルAI 技術調査レポート 2026",
          "Source: Technical Survey Report (Calculated Values based on Weight Quantization)"
        ]
      },
      "citations": [
        {
          "mark": "※48",
          "page": 48,
          "chunk_id": "s048_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "KVキャッシュの支配性（完全版表1）",
          "2k〜32k tokensにおけるメモリ消費量比較（Llama3 8B相当）",
          "[TABLE]",
          "[IMAGE]",
          "設計含意：KVキャッシュはコンテキスト長に比例して線形増加します。32kトークンなどの長文コンテキストでは、FP16のままでは4GBものVRAMを消費し、モデル重み（8B 4bitで約4.5GB）と合わせると8GB VRAMの限界を超えます。FP8/INT4量子化やPaged KV Cacheの導入が、長文運用成立の鍵となります。",
          "[IMAGE]",
          "[5-7]",
          "※計算前提: Llama3 8B (n_layer=32, n_head_kv=8, head_dim=128), GQA有効"
        ]
      },
      "citations": [
        {
          "mark": "※49",
          "page": 49,
          "chunk_id": "s049_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "KVキャッシュの支配性（完全版表2：超長文域）",
          "コンテキスト長131k tokensにおけるメモリ消費量比較（Llama3 8B相当）",
          "[TABLE]",
          "メモリ内訳の逆転現象",
          "[IMAGE]",
          "超長文（128k等）では、KVキャッシュのメモリ消費量がモデル本体（重み）のメモリ消費量を上回る現象が発生します。\n 例：Llama3 8B（4bit重み≒4.1GiB）に対し、131k tokensのKV（FP16）は16.00GiBに達し、総メモリの約80%をKVが占有します。",
          "設計による回避策（Design Implications）",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※50",
          "page": 50,
          "chunk_id": "s050_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "メモリ最適化技術",
      "slots": {
        "TITLE": "メモリ最適化技術",
        "BULLETS": [
          "paged KV／quantized KV／KV reuse／prompt cache",
          "[IMAGE]",
          "KV構造と管理の最適化",
          "[IMAGE]",
          "Paged KV Cache (vLLM)",
          "[IMAGE]",
          "[5]",
          "メモリを固定サイズのページ単位で管理し、断片化を抑制する技術。OSの仮想メモリと同様の仕組みで、GPUメモリの利用効率を劇的に向上させ、スループットを高めます。"
        ]
      },
      "citations": [
        {
          "mark": "※51",
          "page": 51,
          "chunk_id": "s051_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "Tier定義と現実ライン（概要）",
          "ハードウェア別の実用ライン定義",
          "[IMAGE]",
          "結論：Tierは「重み（4bit）＋KV（4k〜8k）＋オーバーヘッド」を前提に定義。\n理論計算値をベースとしつつ、最終判断は実機再現ベンチで行う設計です。",
          "[IMAGE]",
          "Apple Silicon (UMA)",
          "[IMAGE]",
          "16GB (A-16) 3B 〜 7/8B (4bit)"
        ]
      },
      "citations": [
        {
          "mark": "※52",
          "page": 52,
          "chunk_id": "s052_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "Apple Silicon Tier（完全版表1）",
          "実用ライン定義：A-16 / A-24/32 (Unified Memory Architecture)",
          "[TABLE]",
          "[IMAGE]",
          "UMA (Unified Memory Architecture) の特性： CPUとGPUが同一のメモリプールを共有するため、データ転送のオーバーヘッドが極小化されます。Metal Performance Shaders (MPS) バックエンドを使用するMLXやPyTorchの実装では、この統合メモリを効率的に利用できますが、画面表示やOS自身のメモリ消費（数GB）を差し引いた残量が実効VRAMとなる点に注意が必要です。",
          "[IMAGE]",
          "[1,132]",
          "Page 53 | ローカルAI 技術調査レポート 2026"
        ]
      },
      "citations": [
        {
          "mark": "※53",
          "page": 53,
          "chunk_id": "s053_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "Apple Silicon Tier（完全版表2）",
          "A-64 / A-96/128：高品質ローカルの到達点と運用指針",
          "[TABLE]",
          "[IMAGE]",
          "到達点の意味： A-64以上は「妥協のないローカルAI」を実現する領域です。特にUnified Memory Architecture (UMA) の恩恵により、同等VRAMを持つディスクリートGPU構成よりも低コストかつ省電力に大規模モデルを扱えます。ただし、推論速度（スループット）は専用GPUに劣る場合があるため、レイテンシ要件が厳しい場合は量子化レベルの調整やプロンプトキャッシュの活用が重要になります。",
          "Page 54 | ローカルAI 技術調査レポート 2026",
          "Data Source: Technical Survey Report [1, 92, 93, 94]"
        ]
      },
      "citations": [
        {
          "mark": "※54",
          "page": 54,
          "chunk_id": "s054_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "Windows Tier（完全版表1）",
          "W-CPU1 / W-CPU2 / G-8 / G-12 の現実ライン",
          "[TABLE]",
          "[IMAGE]",
          "最適化のポイント：WindowsのCPU推論はIntel拡張（IPEX）やOpenVINO等の最適化が効く場合があります。GPU（G-8/12）では、VRAM不足時にシステムRAMへ溢れると劇的に遅くなるため、タスクマネージャー等でVRAM使用率を厳密に監視してください。",
          "[IMAGE]",
          "[13,135,136]",
          "Page 55 | ローカルAI 技術調査レポート 2026"
        ]
      },
      "citations": [
        {
          "mark": "※55",
          "page": 55,
          "chunk_id": "s055_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "Windows Tier（完全版表2）",
          "高品質・実務用：G-16 (16GB) / G-24 (24GB) 定義",
          "[TABLE]",
          "[IMAGE]",
          "KVキャッシュに関する重要な注意点：\n VRAMに余裕があっても、長文コンテキスト（32k〜128k）を扱うとKVキャッシュがVRAMを大量に消費し、OOM（Out Of Memory）の原因となります。\n G-16/G-24であっても、長文を扱う際は「KV量子化（FP8/INT4）」や「コンテキスト設計（要約・分割）」によるメモリ管理が必須です。",
          "Page 56 | ローカルAI 技術調査レポート 2026",
          "Based on Weight Memory Theory + Reproduction Benchmarks"
        ]
      },
      "citations": [
        {
          "mark": "※56",
          "page": 56,
          "chunk_id": "s056_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "補足：AMD/Intel GPUの現実ライン",
          "公式最適化とエコシステムの現状",
          "[IMAGE]",
          "結論：AMD/Intel環境でも公式最適化による選択肢が存在しますが、運用は実装・ドライバ依存となり、個別検証が必要です。",
          "AMD Radeon GPU (ROCm)",
          "[IMAGE]",
          "ROCm",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※57",
          "page": 57,
          "chunk_id": "s057_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "常駐運用 vs オンデマンド運用",
      "slots": {
        "TITLE": "常駐運用 vs オンデマンド運用",
        "BULLETS": [
          "TTFT（初速）、安定性、リソース効率のトレードオフ",
          "[IMAGE]",
          "基本運用モデルの比較",
          "[IMAGE]",
          "常駐（Always-on）",
          "[IMAGE]",
          "推奨: チャットBot",
          "モデルをメモリに保持し、Prompt Cacheを維持。"
        ]
      },
      "citations": [
        {
          "mark": "※58",
          "page": 58,
          "chunk_id": "s058_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "ユースケース別推奨スタック：音声メモ→整文化→タスク抽出",
          "用途に応じて「低コスト／高品質／ハード制約」の3構成を選択",
          "結論：ASR精度とLLM推論能力のバランスで構成を決定します。 ※誤転記防止にはVAD（無音除去）が必須。タスク抽出にはJSONスキーマ固定が有効です。",
          "[IMAGE]",
          "低コスト構成",
          "Target HW",
          "[IMAGE]",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※59",
          "page": 59,
          "chunk_id": "s059_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "音声メモ→整文化→タスク抽出（失敗モードと回避策）",
          "ユースケース別推奨スタック",
          "[IMAGE]",
          "結論：誤転記・要点漏れ・推論不足は「設計」で抑え込む。\n VADによる区間分割、逐次要約、テンプレ固定が鍵となります。",
          "[IMAGE]",
          "ASR誤転記→抽出ミス",
          "失敗モード",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※60",
          "page": 60,
          "chunk_id": "s060_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "ユースケース：会議議事録（話者分離＋要約＋アクション）",
          "推奨スタック3構成（Tier別）",
          "結論：規模と要件に応じて3構成を選択。無音除去（VAD）と発話ターン統合ルールが品質下限を決定します。\n※評価はp50/p95、RTF、意味改変率で監視することを推奨します。",
          "[IMAGE]",
          "低コスト構成",
          "前処理 (VAD)",
          "[IMAGE]",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※61",
          "page": 61,
          "chunk_id": "s061_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "会議議事録：失敗モードと回避策",
          "ユースケース詳細分析",
          "[IMAGE]",
          "結論：話者誤割当・ASR幻覚・長時間処理の負荷を設計で抑止。\nVAD（無音除去）の厳格化とタイムスタンプベースの検証が品質の防波堤となります。",
          "[IMAGE]",
          "主な失敗モード（Failure Modes）",
          "[IMAGE]",
          "話者誤割当（Diarization Error）"
        ]
      },
      "citations": [
        {
          "mark": "※62",
          "page": 62,
          "chunk_id": "s062_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "ユースケース：文書RAG",
          "PDF/スキャン → OCR → 検索 → 回答",
          "結論：RAG品質はEmbeddingで上限が決まるため、「Embeddingでrecall確保→Rerankerでprecision向上」の二段構えが基本戦略です。",
          "[IMAGE]",
          "低コスト構成",
          "OCR / Pre-process",
          "[IMAGE]",
          "Tesseract OCR ※スキャン品質が高い場合"
        ]
      },
      "citations": [
        {
          "mark": "※63",
          "page": 63,
          "chunk_id": "s063_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "文書RAG：失敗モードと回避策",
          "OCR誤読・検索失敗・幻覚への対策設計",
          "[IMAGE]",
          "結論：文書RAGの失敗は「OCR誤読」「検索精度不足」「幻覚引用」に大別され、 \n前処理の標準化と原文スニペット引用のUX要件化で回避します。",
          "[IMAGE]",
          "主な失敗モード（Failure Modes）",
          "[IMAGE]",
          "スキャン品質低下や傾きにより、固有名詞や数値が誤認識され、正しい文書がヒットしない。"
        ]
      },
      "citations": [
        {
          "mark": "※64",
          "page": 64,
          "chunk_id": "s064_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "ユースケース：画像理解（VLM）— 3構成",
          "スクショ/写真の説明・抽出：推奨スタック比較",
          "結論：2B〜7B級VLMがローカルの現実ライン。72B級は上位機前提となります。\n※視覚トークン肥大による速度/メモリ急落を防ぐため、解像度・max-pixelsの制御が必須です。",
          "[IMAGE]",
          "低コスト構成",
          "Target HW",
          "[IMAGE]",
          "Apple 16GB / VRAM 8GB級"
        ]
      },
      "citations": [
        {
          "mark": "※65",
          "page": 65,
          "chunk_id": "s065_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "画像理解：失敗モードと回避策",
          "ユースケース別推奨スタック（詳細）",
          "[IMAGE]",
          "結論：UI文字の誤読と視覚トークン肥大による速度低下を、\nOCR併用と解像度・max-pixels制御で回避します。",
          "[IMAGE]",
          "主な失敗モード（Failure Modes）",
          "[IMAGE]",
          "2B/7B級VLMでは、スクリーンショット内の小さなフォントや密集した情報を正確に読み取れないケースが頻発。"
        ]
      },
      "citations": [
        {
          "mark": "※66",
          "page": 66,
          "chunk_id": "s066_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "ユースケース：コーディング補助",
          "推奨スタック3パターン（IDE支援・リポジトリ理解）",
          "結論：補完は小型モデル、設計レビューや長距離依存解決は中〜大型モデルで役割分担します。\n※生成コードは自動コンパイル/テスト実行を“ツール”化し、検証ループに組み込むことが重要です。",
          "[IMAGE]",
          "低コスト構成",
          "Code LLM",
          "[IMAGE]",
          "Qwen2.5-Coder 7B サイズ展開が豊富で軽量"
        ]
      },
      "citations": [
        {
          "mark": "※67",
          "page": 67,
          "chunk_id": "s067_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "コーディング支援：失敗モードと回避策",
          "コーディング補助（IDE支援・リポジトリ理解）",
          "[IMAGE]",
          "結論：幻覚API生成と長文遅延を「検証ループ」と「キャッシュ活用」で抑止し、 \n コード品質とセキュリティを自動化プロセスで担保します。",
          "[IMAGE]",
          "主な失敗モード（Failure Modes）",
          "[IMAGE]",
          "ライブラリのバージョン不一致や、もっともらしいが実在しない関数（Hallucination）を生成。"
        ]
      },
      "citations": [
        {
          "mark": "※68",
          "page": 68,
          "chunk_id": "s068_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "ユースケース：画像生成（Diffusion）— 3構成",
          "推奨スタックとVRAM要件の最適化",
          "結論：SDXLを軸にComfyUIでワークフローを資産化。FLUX等はライセンス精査が必須です。\n※VRAM要件は解像度・バッチ・ステップ数に依存するため、プロファイル固定が重要です。",
          "[IMAGE]",
          "低コスト構成",
          "Target VRAM",
          "[IMAGE]",
          "VRAM 8GB〜12GB\n(Apple Silicon 16GB)"
        ]
      },
      "citations": [
        {
          "mark": "※69",
          "page": 69,
          "chunk_id": "s069_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "画像生成：失敗モードと回避策",
          "VRAM制約と品質・ライセンス管理",
          "[IMAGE]",
          "結論：VRAM不足と生成結果のブレを「標準プロファイル」で抑制し、 \n ライセンス違反リスクを「事前精査と監査」で排除します。",
          "[IMAGE]",
          "主な失敗モード（Failure Modes）",
          "[IMAGE]",
          "高解像度や大バッチ指定時にプロセスがクラッシュ。特にSDXL/FLUX等の大型モデルで頻発。"
        ]
      },
      "citations": [
        {
          "mark": "※70",
          "page": 70,
          "chunk_id": "s070_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "10",
          "[IMAGE]",
          "測定と比較の\n方法",
          "ベンチマーク設計と\n再現性の担保",
          "KEY TAKEAWAYS",
          "[IMAGE]",
          "本章の要点",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※71",
          "page": 71,
          "chunk_id": "s071_sh003"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "測定指標の定義",
          "p50/p95・TTFT・tok/s・RTF・品質指標",
          "[IMAGE]",
          "結論：LLMの「初速（TTFT）」と「生成速度（tok/s）」を分離して計測し、\n 品質（JSON破壊率等）とリソース消費（RAM/VRAM）を定量化します。",
          "[IMAGE]",
          "速度・リソース指標（Latency & Resource）",
          "[IMAGE]",
          "TTFT（Time To First Token）と生成完了時間を分離して計測。KV reuseやprompt cacheの効果はTTFTに現れるため分離が必須。"
        ]
      },
      "citations": [
        {
          "mark": "※72",
          "page": 72,
          "chunk_id": "s072_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "測定手順（条件固定・ウォームアップ・KV切り分け）",
      "slots": {
        "TITLE": "測定手順（条件固定・ウォームアップ・KV切り分け）",
        "BULLETS": [
          "再現可能なベンチマーク設計の要件",
          "[IMAGE]",
          "再現条件の固定",
          "[IMAGE]",
          "生成パラメータの統一",
          "同一プロンプト、最大トークン数、温度（temperature）、top_p を固定し、ランダム性を排除または制御します。",
          "[IMAGE]",
          "モデル環境の固定"
        ]
      },
      "citations": [
        {
          "mark": "※73",
          "page": 73,
          "chunk_id": "s073_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "リスクとコンプライアンス",
          "ライセンス管理・プライバシー・安全性対策",
          "[IMAGE]",
          "結論：「コードのOSSライセンス」と「モデル重みの利用条件」を分離管理し、ローカル完結の利点を活かしつつ、検証ループによる安全性確保が必須です。",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]",
          "[IMAGE]"
        ]
      },
      "citations": [
        {
          "mark": "※74",
          "page": 74,
          "chunk_id": "s074_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "まとめ（意思決定フロー）",
          "ローカルAI導入の5ステップと判断基準",
          "[IMAGE]",
          "1",
          "要件定義\nRequirements",
          "Requirements",
          "業務課題から技術要件へ変換する始点。",
          "判断基準 (Criteria)"
        ]
      },
      "citations": [
        {
          "mark": "※75",
          "page": 75,
          "chunk_id": "s075_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "総括（実務への適用）",
          "実装の原則と次のステップ",
          "[IMAGE]",
          "結論：ローカルAIは「4bit量子化＋KV最適化」を前提に、 \n 失敗モードを設計で抑え込むことで実務運用が可能です。",
          "[IMAGE]",
          "実装の原則（Principles）",
          "[IMAGE]",
          "重みは4bit（GGUF/AWQ/GPTQ）でメモリ理論値を計算し、Tierに合わせる。"
        ]
      },
      "citations": [
        {
          "mark": "※76",
          "page": 76,
          "chunk_id": "s076_sh005"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "References（1/4）",
          "Technical Research Report Sources [1-34]",
          "[1]",
          "https://www.apple.com/newsroom/2020/11/apple-unleashes-m1/",
          "[2]",
          "https://docs.openhands.dev/openhands/usage/llms/local-llms",
          "[3]",
          "https://lmstudio.ai/docs/developer/core/server"
        ]
      },
      "citations": [
        {
          "mark": "※77",
          "page": 77,
          "chunk_id": "s077_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "References（参考文献リスト 2/4）",
          "[35]～[68] Llama / Qwen / Gemma / Phi / VLM / Whisper / TTS / OCR",
          "[TABLE]",
          "[TABLE]",
          "Page 78 | ローカルAI 技術調査レポート 2026",
          "Reference List [35-68]"
        ]
      },
      "citations": [
        {
          "mark": "※78",
          "page": 78,
          "chunk_id": "s078_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "References（3/4）",
          "参考文献リスト [69] - [102]",
          "[TABLE]",
          "[TABLE]",
          "Page 79 | ローカルAI 技術調査レポート 2026",
          "Data Source: Technical Survey Report"
        ]
      },
      "citations": [
        {
          "mark": "※79",
          "page": 79,
          "chunk_id": "s079_sh004"
        }
      ]
    },
    {
      "slide_no": null,
      "component_id": "comp_title_bullets",
      "message": "[IMAGE]",
      "slots": {
        "TITLE": "[IMAGE]",
        "BULLETS": [
          "References（参考文献リスト4/4）",
          "音声周辺・ベンチマーク・最適化技術・ハードウェア関連 [103] - [136]",
          "[TABLE]",
          "[TABLE]",
          "完",
          "Page 80 | ローカルAI 技術調査レポート 2026",
          "Technical Survey Completed."
        ]
      },
      "citations": [
        {
          "mark": "※80",
          "page": 80,
          "chunk_id": "s080_sh004"
        }
      ]
    }
  ],
  "toc": [
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 1
    },
    {
      "title": "このスライドの読み方",
      "level": 1,
      "slide_index": 2
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 3
    },
    {
      "title": "エグゼクティブサマリ（実務要点）",
      "level": 1,
      "slide_index": 4
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 5
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 6
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 7
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 8
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 9
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 10
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 11
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 12
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 13
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 14
    },
    {
      "title": "特徴軸（詳細）：測定と設計含意",
      "level": 1,
      "slide_index": 15
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 16
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 17
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 18
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 19
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 20
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 21
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 22
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 23
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 24
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 25
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 26
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 27
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 28
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 29
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 30
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 31
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 32
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 33
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 34
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 35
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 36
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 37
    },
    {
      "title": "\\\\n\\\\n採用判断基準（画像生成）\\\\n",
      "level": 1,
      "slide_index": 38
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 39
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 40
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 41
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 42
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 43
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 44
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 45
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 46
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 47
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 48
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 49
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 50
    },
    {
      "title": "メモリ最適化技術",
      "level": 1,
      "slide_index": 51
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 52
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 53
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 54
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 55
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 56
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 57
    },
    {
      "title": "常駐運用 vs オンデマンド運用",
      "level": 1,
      "slide_index": 58
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 59
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 60
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 61
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 62
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 63
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 64
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 65
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 66
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 67
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 68
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 69
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 70
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 71
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 72
    },
    {
      "title": "測定手順（条件固定・ウォームアップ・KV切り分け）",
      "level": 1,
      "slide_index": 73
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 74
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 75
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 76
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 77
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 78
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 79
    },
    {
      "title": "[IMAGE]",
      "level": 1,
      "slide_index": 80
    }
  ]
}